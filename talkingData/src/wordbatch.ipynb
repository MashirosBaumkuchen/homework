{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordbatch.extractors.extractors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-83a1d1a57530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../input/lib/randomstate/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordHash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwordbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFM_FTRL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwordbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/hp/ML/talk/input/lib/wordbatch/wordbatch/extractors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextractors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordbatch.extractors.extractors'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../input/lib/wordbatch/')\n",
    "sys.path.insert(0, '../input/lib/randomstate/')\n",
    "import wordbatch\n",
    "from wordbatch.extractors import WordHash\n",
    "from wordbatch.models import FM_FTRL\n",
    "from wordbatch.data_utils import *\n",
    "import threading\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "import os, psutil\n",
    "def cpuStats():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0] / 2. ** 30\n",
    "    print('memory GB:', memoryUse)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mean_auc= 0\n",
    "\n",
    "def fit_batch(clf, X, y, w):  clf.partial_fit(X, y, sample_weight=w)\n",
    "\n",
    "def predict_batch(clf, X):  return clf.predict(X)\n",
    "\n",
    "def evaluate_batch(clf, X, y, rcount):\n",
    "    auc= roc_auc_score(y, predict_batch(clf, X))\n",
    "    global mean_auc\n",
    "    if mean_auc==0:\n",
    "        mean_auc= auc\n",
    "    else: mean_auc= 0.2*(mean_auc*4 + auc)\n",
    "    print(rcount, \"ROC AUC:\", auc, \"Running Mean:\", mean_auc)\n",
    "    return auc\n",
    "\n",
    "def df_add_counts(df, cols):\n",
    "    arr_slice = df[cols].values\n",
    "    unq, unqtags, counts = np.unique(np.ravel_multi_index(arr_slice.T, arr_slice.max(0) + 1),return_inverse=True, return_counts=True)\n",
    "    df[\"_\".join(cols)+'_count'] = counts[unqtags]\n",
    "\n",
    "def df2csr(wb, df, pick_hours=None):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    with timer(\"Adding counts\"):\n",
    "        df['click_time']= pd.to_datetime(df['click_time'])\n",
    "        dt= df['click_time'].dt\n",
    "        df['day'] = dt.day.astype('uint8')\n",
    "        df['hour'] = dt.hour.astype('uint8')\n",
    "        del(dt)\n",
    "        df_add_counts(df, ['ip', 'day', 'hour'])\n",
    "        df_add_counts(df, ['ip', 'app'])\n",
    "        df_add_counts(df, ['ip', 'app', 'os'])\n",
    "        df_add_counts(df, ['ip', 'device'])\n",
    "        df_add_counts(df, ['app', 'channel'])\n",
    "        #cpuStats()\n",
    "\n",
    "    with timer(\"Adding next click times\"):\n",
    "        D= 2**26\n",
    "        df['category'] = (df['ip'].astype(str) + \"_\" + df['app'].astype(str) + \"_\" + df['device'].astype(str) \\\n",
    "                          + \"_\" + df['os'].astype(str) + \"_\" + df['channel'].astype(str)).apply(hash) % D\n",
    "        click_buffer= np.full(D, 3000000000, dtype=np.uint32)\n",
    "        df['epochtime']= df['click_time'].astype(np.int64) // 10 ** 9\n",
    "        next_clicks= []\n",
    "        for category, time in zip(reversed(df['category'].values), reversed(df['epochtime'].values)):\n",
    "            next_clicks.append(click_buffer[category]-time)\n",
    "            click_buffer[category]= time\n",
    "        del(click_buffer)\n",
    "        df['next_click']= list(reversed(next_clicks))\n",
    "\n",
    "    for fea in ['ip_day_hour_count','ip_app_count','ip_app_os_count','ip_device_count','app_channel_count','next_click']:  \n",
    "        df[fea]= np.log2(1 + df[fea].values).astype(int)\n",
    "\n",
    "    with timer(\"Generating str_array\"):\n",
    "        str_array= (\"I\" + df['ip'].astype(str) \\\n",
    "            + \" A\" + df['app'].astype(str) \\\n",
    "            + \" D\" + df['device'].astype(str) \\\n",
    "            + \" O\" + df['os'].astype(str) \\\n",
    "            + \" C\" + df['channel'].astype(str) \\\n",
    "            + \" WD\" + df['day'].astype(str) \\\n",
    "            + \" H\" + df['hour'].astype(str) \\\n",
    "            + \" AXC\" + df['app'].astype(str)+\"_\"+df['channel'].astype(str) \\\n",
    "            + \" OXC\" + df['os'].astype(str)+\"_\"+df['channel'].astype(str) \\\n",
    "            + \" AXD\" + df['app'].astype(str)+\"_\"+df['device'].astype(str) \\\n",
    "            + \" AXOCXC\" + df['app'].astype(str)+\"_\"+df['os'].astype(str) \\\n",
    "            +\"_\"+df['channel'].astype(str) \\\n",
    "            + \" IXA\" + df['ip'].astype(str)+\"_\"+df['app'].astype(str) \\\n",
    "            + \" AXO\" + df['app'].astype(str)+\"_\"+df['os'].astype(str) \\\n",
    "            + \" IDHC\" + df['ip_day_hour_count'].astype(str) \\\n",
    "            + \" IAC\" + df['ip_app_count'].astype(str) \\\n",
    "            + \" AOC\" + df['ip_app_os_count'].astype(str) \\\n",
    "            + \" IDC\" + df['ip_device_count'].astype(str) \\\n",
    "            + \" AC\" + df['app_channel_count'].astype(str) \\\n",
    "            + \" NC\" + df['next_click'].astype(str)\n",
    "            ).values\n",
    "    #cpuStats()\n",
    "    if 'is_attributed' in df.columns:\n",
    "        labels = df['is_attributed'].values\n",
    "        weights = np.multiply([1.0 if x == 1 else 0.2 for x in df['is_attributed'].values],df['hour'].apply(lambda x: 1.0 if x in pick_hours else 0.5))\n",
    "    else:\n",
    "        labels = []\n",
    "        weights = []\n",
    "    return str_array, labels, weights\n",
    "\n",
    "class ThreadWithReturnValue(threading.Thread):\n",
    "    def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None):\n",
    "        threading.Thread.__init__(self, group, target, name, args, kwargs, daemon=daemon)\n",
    "        self._return = None\n",
    "    def run(self):\n",
    "        if self._target is not None:\n",
    "            self._return = self._target(*self._args, **self._kwargs)\n",
    "    def join(self):\n",
    "        threading.Thread.join(self)\n",
    "        return self._return\n",
    "\n",
    "batchsize = 10000000\n",
    "D = 2 ** 22\n",
    "\n",
    "wb = wordbatch.WordBatch(None, extractor=(WordHash, {\"ngram_range\": (1, 1), \"analyzer\": \"word\",\n",
    "                                                    \"lowercase\": False, \"n_features\": D,\n",
    "                                                    \"norm\": None, \"binary\": True})\n",
    "                         , minibatch_size=batchsize // 80, procs=8, freeze=True, timeout=1800, verbose=0)\n",
    "clf = FM_FTRL(alpha=0.05, beta=0.1, L1=0.0, L2=0.0, D=D, alpha_fm=0.02, L2_fm=0.0, init_fm=0.01, weight_fm=1.0,\n",
    "                 D_fm=8, e_noise=0.0, iters=3, inv_link=\"sigmoid\", e_clip=1.0, threads=4, use_avx=1, verbose=0)\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        }\n",
    "\n",
    "p = None\n",
    "rcount = 0\n",
    "for df_c in pd.read_csv('../input/train.csv', engine='c', chunksize=batchsize,\n",
    "#for df_c in pd.read_csv('../input/train.csv', engine='c', chunksize=batchsize,\n",
    "                        sep=\",\", dtype=dtypes):\n",
    "    rcount += batchsize\n",
    "    #cpuStats()\n",
    "    str_array, labels, weights= df2csr(wb, df_c, pick_hours={4, 5, 10, 13, 14})\n",
    "    del(df_c)\n",
    "    if p != None:\n",
    "        p.join()\n",
    "        del(X)\n",
    "    gc.collect()\n",
    "    X= wb.transform(str_array)\n",
    "    del(str_array)\n",
    "    if rcount % (2 * batchsize) == 0:\n",
    "        if p != None:  p.join()\n",
    "        p = threading.Thread(target=evaluate_batch, args=(clf, X, labels, rcount))\n",
    "        p.start()\n",
    "    print(\"Training\", rcount, time.time() - start_time)\n",
    "    cpuStats()\n",
    "    if p != None:  p.join()\n",
    "    p = threading.Thread(target=fit_batch, args=(clf, X, labels, weights))\n",
    "    p.start()\n",
    "if p != None:  p.join()\n",
    "\n",
    "p = None\n",
    "click_ids= []\n",
    "test_preds = []\n",
    "rcount = 0\n",
    "for df_c in pd.read_csv('../input/test.csv', engine='c', chunksize=batchsize,\n",
    "#for df_c in pd.read_csv('../input/test.csv', engine='c', chunksize=batchsize,\n",
    "                        sep=\",\", dtype=dtypes):\n",
    "    rcount += batchsize\n",
    "    if rcount % (10 * batchsize) == 0:\n",
    "        print(rcount)\n",
    "    str_array, labels, weights = df2csr(wb, df_c)\n",
    "    click_ids+= df_c['click_id'].tolist()\n",
    "    del(df_c)\n",
    "    if p != None:\n",
    "        test_preds += list(p.join())\n",
    "        del (X)\n",
    "    gc.collect()\n",
    "    X = wb.transform(str_array)\n",
    "    del (str_array)\n",
    "    p = ThreadWithReturnValue(target=predict_batch, args=(clf, X))\n",
    "    p.start()\n",
    "if p != None:  test_preds += list(p.join())\n",
    "\n",
    "df_sub = pd.DataFrame({\"click_id\": click_ids, 'is_attributed': test_preds})\n",
    "df_sub.to_csv(\"../output/wordbatch_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../input/wordbatch/wordbatch/')\n",
    "sys.path.insert(0, '../input/wordbatch/randomstate/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/wordbatch/randomstate/',\n",
       " '../input/wordbatch/wordbatch/',\n",
       " '../input/wordbatch/randomstate/',\n",
       " '../input/wordbatch/wordbatch/',\n",
       " '../input/wordbatch/randomstate/',\n",
       " '../input/wordbatch/wordbatch/',\n",
       " '',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.6/lib/python36.zip',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/lib-dynload',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/jascal/.ipython']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jascal/Desktop/hp/ML/talk/input/wordbatch/wordbatch\n"
     ]
    }
   ],
   "source": [
    "cd ../input/wordbatch/wordbatch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py    data_utils.py  \u001b[34mmodels\u001b[m\u001b[m/\r\n",
      "batcher.py     \u001b[34mextractors\u001b[m\u001b[m/    wordbatch.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordbatch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
